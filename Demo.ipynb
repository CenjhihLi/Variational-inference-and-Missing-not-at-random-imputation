{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 6>**\n",
    "# This is the `Demo.ipynb` file\n",
    "\n",
    "I will demonstrate how to use my classes and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 4>**\n",
    "# The `UCIDatasets` loader in `/utils/dataframe.py `\n",
    "\n",
    "`reference: https://gist.github.com/martinferianc/db7615c85d5a3a71242b4916ea6a14a2`\n",
    "\n",
    "Note that the output `train` or `test` is pytorch.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['housing', 'concrete', 'energy', 'power', 'redwine', 'whitewine', 'yacht']\n"
     ]
    }
   ],
   "source": [
    "from utils.dataframe import UCIDatasets, datalist\n",
    "print(datalist)\n",
    "data = UCIDatasets(\"housing\")\n",
    "train = data.get_split( load=\"train\") #pytorch.dataset\n",
    "test = data.get_split( load=\"test\")\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_loader = data.get_dataloader(load = \"train\", batch_size = 16) #pytorch.dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 4>**\n",
    "# The `imputer` in `model/imputer.py`.\n",
    "\n",
    "I assemble several common methods, some detail can see my code and the documentary of sklearn.impute. \n",
    "\n",
    "I have set up some parameters. change the parameters via `par_setting( par_dict )` function.\n",
    "\n",
    "The input dictionary should be like `__getParvalue__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean', 'median', 'most_frequent', 'mice', 'missForest', 'knn']\n",
      "\n",
      "\n",
      "Set up parameters via impObject.par_setting( par_dict ) and retrain the model,     the par_dict should be like the following structure:\n",
      " {'missing_values': nan, 'max_iter': 10, 'random_state': 0, 'n_estimators': 100, 'n_neighbors': 3, 'metric': 'nan_euclidean'} \n",
      "\n",
      "for instance: impObject.par_setting( { 'max_iter': 10 } ) \n",
      "\n",
      "Each par corresponding to method is as the following:\n",
      "where SimpleImputer includes ['mean', 'median', 'most_frequent']\n"
     ]
    }
   ],
   "source": [
    "from model.imputer import imputer, method_list\n",
    "import numpy as np\n",
    "print(method_list)\n",
    "X = np.random.rand(100*20).reshape(100,20)\n",
    "X[51:, 11:] = np.nan\n",
    "\n",
    "impObject = imputer(X, method = 'mice')\n",
    "impObject.train()\n",
    "imp = impObject.imp\n",
    "imp.transform(X).shape \n",
    "print('\\n\\nSet up parameters via impObject.par_setting( par_dict ) and retrain the model, \\\n",
    "    the par_dict should be like the following structure:\\n {} \\n'.format(impObject.getParvalue()))\n",
    "print('for instance: impObject.par_setting( { \\'max_iter\\': 10 } ) ')\n",
    "print('\\nEach par corresponding to method is as the following:')\n",
    "impObject.getParlist()\n",
    "print('where SimpleImputer includes [\\'mean\\', \\'median\\', \\'most_frequent\\']')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 4>**\n",
    "# This part is for `MIWAE` in `/model/MIWAE.py` and `trainer` in `/utils/trainer.py`.\n",
    "\n",
    "`http://proceedings.mlr.press/v97/mattei19a/mattei19a.pdf (ICML, 2019)`.\n",
    "\n",
    "`MIWAE` is a pytorch model\n",
    "\n",
    "Might use `trainer` to train it.\n",
    "\n",
    "Loss function are like `loss(self, outdic, indic)` in which outdic and indic are input and output\n",
    "\n",
    "For `MIWAE`, \n",
    "\n",
    "`indic = {'x': x , 'm': m }` where `x` is dataset and `m` is missing indicator.\n",
    "\n",
    "`output = {'lpxz': lpxz , 'lqzx': lqzx , 'lpz': lpz }`  means `l`og loss for `p`(`x` | `z`), `q`(`z` | `x`), `p`(`z`)\n",
    "\n",
    "In MIWAE loss `self.MIWAE_ELBO(outdic, indic = None)` the indic is not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es torch.Size([16, 20, 20])\n",
      "Esx torch.Size([16, 20, 21])\n",
      "Esxr torch.Size([320, 21])\n",
      "h torch.Size([320, 20])\n",
      "hr torch.Size([16, 20, 20])\n",
      "hz torch.Size([16, 20, 20])\n",
      "g torch.Size([16, 20])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 20]             440\n",
      "            Linear-2                  [-1, 100]           2,100\n",
      "              Tanh-3                  [-1, 100]               0\n",
      "            Linear-4                  [-1, 100]          10,100\n",
      "              Tanh-5                  [-1, 100]               0\n",
      "            Linear-6                   [-1, 50]           5,050\n",
      "            Linear-7                   [-1, 50]           5,050\n",
      "            Linear-8               [-1, 5, 100]           5,100\n",
      "            Linear-9               [-1, 5, 100]          10,100\n",
      "           Linear-10                [-1, 5, 20]           2,020\n",
      "           Linear-11                [-1, 5, 20]           2,020\n",
      "================================================================\n",
      "Total params: 41,980\n",
      "Trainable params: 41,980\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from model.MIWAE import MIWAE\n",
    "from utils.trainer import VAEtrainer\n",
    "from utils.dataframe import UCIDatasets, datalist\n",
    "data = UCIDatasets(\"whitewine\")\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_loader = data.get_dataloader(load = \"train\", batch_size = 16) #pytorch.dataloader\n",
    "test_loader = data.get_dataloader(load = \"test\", batch_size = 16) #pytorch.dataloader\n",
    "model = MIWAE(data_dim = 20, n_samples=5, permutation_invariance=True)\n",
    "trainer = VAEtrainer(model = model, train_loader = train_loader, test_loader = test_loader)\n",
    "trainer.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 4>**\n",
    "# A simple example\n",
    "\n",
    "Here is a simple example using `/utils/VAEtrainer` class from `/utils/trainer.py` to train `VAE` on `MNIST`.\n",
    "\n",
    "First, we may set some hyperparameters.\n",
    "\n",
    "Then read the training data and validation data (`train_loader` structure) and put them into trainer.\n",
    "\n",
    "The trainer will use `VAE_loss` automatically for `VAE` model.\n",
    "\n",
    "I will use this trainer for all `VAE` like models in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 550.596191\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 306.821533\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 239.735840\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 219.265381\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 215.173080\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 207.980484\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 205.002518\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 195.018509\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 195.951401\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 191.046799\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 177.746704\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 173.476212\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 182.252777\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 168.943054\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 167.080704\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 163.089127\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 161.482941\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 152.580917\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 156.822372\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 154.286819\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 154.853256\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 150.406219\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 154.873795\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 147.339737\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 141.410080\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 144.210587\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 145.480576\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 144.594559\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 136.373703\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 142.608658\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 139.442032\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 134.519348\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 143.254120\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 140.897766\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 141.616852\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 136.011932\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 141.075958\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 132.051727\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 132.235733\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 131.391937\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 132.229904\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 131.997971\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 132.772461\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 127.136108\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 137.615433\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 130.764771\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 133.248978\n",
      "====> Epoch: 1 Average loss: 164.8244\n",
      "====> Test set loss: 128.5144\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 130.626587\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 132.458313\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 133.380127\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 133.654083\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 132.735901\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 126.095322\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 130.791840\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 125.040657\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 129.756027\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 126.176445\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 122.222351\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 123.960831\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 122.330193\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 125.502441\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 117.070885\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 117.767700\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 122.772247\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 119.136932\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 120.087204\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 126.980331\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 124.642822\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 124.310318\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 118.050751\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 117.935349\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 120.840057\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 123.109077\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 122.826744\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 110.336357\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 123.963577\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 117.607346\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 119.557068\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 119.142509\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 122.492310\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 120.630791\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 119.739685\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 117.440048\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 117.436539\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 119.404854\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 118.541527\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 119.587082\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 119.653290\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 119.965408\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 112.638741\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 118.882355\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 115.701683\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 114.951050\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 119.145607\n",
      "====> Epoch: 2 Average loss: 122.3092\n",
      "====> Test set loss: 116.4054\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 119.131638\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 118.047440\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 109.468491\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 119.619232\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 112.592598\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 112.815079\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 113.274490\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 115.308563\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 115.314445\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 116.420334\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 120.511429\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 121.338493\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 118.486259\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 118.363770\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 109.248657\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 118.421837\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 117.478226\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 117.293190\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 112.233765\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 114.245560\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 114.691025\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 113.223541\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 114.466843\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 117.562408\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 116.119888\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 115.274513\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 111.417320\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 113.641815\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 114.212570\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 111.608521\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 116.207466\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 110.958908\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 110.443230\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 110.575111\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 114.892921\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 116.212753\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 115.157036\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 113.615776\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 113.346298\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 115.483803\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 113.011276\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 111.189514\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 115.409874\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 112.347153\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 114.825653\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 111.366928\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 116.531776\n",
      "====> Epoch: 3 Average loss: 114.9204\n",
      "====> Test set loss: 111.9082\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 118.462143\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 113.987488\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 111.360443\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 113.629761\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 118.349548\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 114.890694\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 113.079002\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 113.261528\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 112.671799\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 111.480438\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 111.478096\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 114.053200\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 112.444786\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 109.647018\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 109.595840\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 116.061096\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 109.978027\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 115.266983\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 108.624359\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 108.250832\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 113.824532\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 113.285324\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 109.382797\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 112.999931\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 111.670670\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 106.605087\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 110.042526\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 114.572197\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 113.400528\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 113.465202\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 116.273300\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 113.874100\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 114.011238\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 109.458176\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 111.850616\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 111.494553\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 111.391159\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 109.224068\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 111.177490\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 111.905037\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 110.595306\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 110.787659\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 108.241241\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 107.880684\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 110.493851\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 111.860573\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 109.022598\n",
      "====> Epoch: 4 Average loss: 111.6956\n",
      "====> Test set loss: 110.5553\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 109.547241\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 105.443260\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 109.186966\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 105.082405\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 109.601456\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 111.456497\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 110.739464\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 114.240623\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 106.998589\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 109.149902\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 108.650024\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 113.884460\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 109.328934\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 108.752625\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 114.207954\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 109.897766\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 113.972260\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 110.928368\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 107.777115\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 113.593002\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 105.318443\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 109.434814\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 106.650452\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 110.142487\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 106.883759\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 104.803452\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 108.925575\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 110.584808\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 107.421608\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 106.680138\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 112.940430\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 110.834427\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 112.251442\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 111.542381\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 109.812637\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 111.060555\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 108.193985\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 110.186523\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 109.768890\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 105.476349\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 106.940125\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 104.995270\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 107.522659\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 112.098793\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 112.498344\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 106.950897\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 110.525482\n",
      "====> Epoch: 5 Average loss: 109.8703\n",
      "====> Test set loss: 108.3903\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 110.075340\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 105.481766\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 106.472504\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 110.917068\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 108.866806\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 107.964905\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 112.298805\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 110.215500\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 108.775375\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 109.446213\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 103.916245\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 110.025589\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 111.350784\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 107.084549\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 109.200165\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 112.032051\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 106.819267\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 108.489716\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 107.086319\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 106.402184\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 104.802498\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 110.307953\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 108.800018\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 107.340126\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 106.232552\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 106.506706\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 107.318527\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 103.072418\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 108.947372\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 113.495560\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 113.621262\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 105.887360\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 105.237419\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 108.183311\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 109.424408\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 104.716255\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 112.381271\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 109.581558\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 109.849350\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 108.311874\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 107.659431\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 108.930557\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 107.649025\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 108.517921\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 106.108101\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 110.431992\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 108.045944\n",
      "====> Epoch: 6 Average loss: 108.6580\n",
      "====> Test set loss: 107.6233\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 109.944839\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 106.366402\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 112.204384\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 105.932266\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 111.758774\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 108.867142\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 105.891739\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 105.639603\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 108.328537\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 109.171562\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 108.712875\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 106.296410\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 108.016083\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 106.572716\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 105.735443\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 110.577271\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 106.583611\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 105.191383\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 107.003677\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 109.390381\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 109.700844\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 107.635223\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 105.144646\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 104.448288\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 105.461525\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 109.906837\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 106.812798\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 108.892891\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 106.687180\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 108.457687\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 111.361656\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 105.424660\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 105.913483\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 103.278938\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 112.417915\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 107.916397\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 112.198074\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 110.294342\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 105.999527\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 106.901695\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 110.222504\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 109.836067\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 106.087067\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 105.557846\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 105.729004\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 108.390778\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 107.314957\n",
      "====> Epoch: 7 Average loss: 107.8095\n",
      "====> Test set loss: 107.2324\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 108.835037\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 102.944397\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 109.136253\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 106.487885\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 109.057129\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 109.106613\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 107.456924\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 108.640213\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 106.081131\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 106.441910\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 109.514389\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 110.510956\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 109.720673\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 108.503540\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 106.419090\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 107.208855\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 105.594322\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 105.289001\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 105.140450\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 110.244583\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 104.317818\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 107.697174\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 106.929214\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 110.551155\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 103.973358\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 108.301491\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 106.161758\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 106.760529\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 109.925430\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 110.971725\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 106.419136\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 104.774055\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 106.274940\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 108.347565\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 104.869644\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 107.580482\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 108.276215\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 108.514091\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 105.619949\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 106.406601\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 106.183090\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 108.840363\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 108.973404\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 107.691551\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 104.856995\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 107.544907\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 104.804230\n",
      "====> Epoch: 8 Average loss: 107.1775\n",
      "====> Test set loss: 106.5009\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 105.367447\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 103.271492\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 106.692482\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 107.413200\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 108.141075\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 108.323418\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 105.361244\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 104.803009\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 104.306915\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 103.413429\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 105.889862\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 102.904709\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 106.782623\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 107.824257\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 109.381622\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 108.813042\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 106.642097\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 107.159340\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 106.855011\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 106.037056\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 105.813423\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 105.491592\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 106.726715\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 108.171600\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 104.795288\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 106.275459\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 108.128868\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 107.725777\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 108.441315\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 103.774536\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 108.998016\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 106.759674\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 105.456596\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 106.758064\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 110.046387\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 107.659500\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 105.457497\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 110.379997\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 108.212540\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 103.310165\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 103.355240\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 105.107445\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 107.725891\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 107.453407\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 102.846100\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 105.982300\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 109.024834\n",
      "====> Epoch: 9 Average loss: 106.6282\n",
      "====> Test set loss: 105.8009\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 107.849754\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 107.868973\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 106.729538\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 104.727211\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 109.574600\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 105.885452\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 107.381996\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 109.233925\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 108.407578\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 103.433380\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 107.896576\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 109.105736\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 109.491150\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 101.481155\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 107.220917\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 106.454292\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 107.919464\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 106.811874\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 104.978539\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 102.114479\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 107.906624\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 104.093643\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 105.435417\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 106.657898\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 106.017250\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 105.531036\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 103.853958\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 104.186790\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 104.787224\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 103.583275\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 107.150803\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 110.465157\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 106.218742\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 105.964920\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 102.980309\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 108.511360\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 106.928246\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 106.501266\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 105.735039\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 108.042038\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 104.949013\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 108.999153\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 106.618813\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 108.723694\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 107.029289\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 105.807549\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 106.311470\n",
      "====> Epoch: 10 Average loss: 106.2131\n",
      "====> Test set loss: 105.5583\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "from model.VAE import VAE\n",
    "from utils.trainer import VAEtrainer\n",
    "\n",
    "batch_size=128\n",
    "max_epochs=10\n",
    "no_cuda = False\n",
    "seed=1\n",
    "log_interval=10\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, num_workers = 1, pin_memory = True )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, num_workers = 1, pin_memory = True)\n",
    "\n",
    "model = VAE()\n",
    "trainer = VAEtrainer(model = model, train_loader = train_loader, test_loader= test_loader, batch_size = batch_size)\n",
    "trainer.train(max_epochs = max_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6db9b13bbeaa7901a248048a8ac684b541578b3064e63ac00ea1c7bbcba68952"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
